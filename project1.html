<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Project 1</title>
  <link rel="stylesheet" href="styles.css"> <!-- Link to your stylesheet -->
  <style>
    /* CSS for image background */
    body {
      margin: 0; /* Remove default body margin */
      padding: 0; /* Remove default body padding */
      background-image: url('music1.jpg'); /* Set background image */
      background-size: cover; /* Cover the entire viewport */
      background-position: center; /* Center the background image */
      color: #000; /* Text color (black) */
    }

    header {
      background-color: rgba(0, 0, 0, 0.5); /* Add semi-transparent background for better readability */
      padding: 20px; /* Add padding to the header */
    }

    #project-details {
      padding: 20px; /* Add padding to the project details section */
      max-width: 800px; /* Limit the maximum width of the content */
      margin: 0 auto; /* Center the content horizontally */
    }

    #project-details h2 {
      margin-bottom: 20px; /* Add spacing below the project title */
    }

    #project-details p {
      margin-bottom: 20px; /* Add spacing between paragraphs */
      text-align: justify; /* Justify the text */
    }
  </style>
</head>
<body>
  <header>
    <h1>Project 1</h1>
    <nav>
      <ul>
        <li><a href="index.html">Home</a></li>
        <li><a href="about.html">About</a></li>
        <li><a href="projects.html">Projects</a></li>
        <li><a href="contact.html">Contact</a></li>
      </ul>
    </nav>
  </header>

  <section id="project-details">
    <h2>
      TITLE: Music Recommendation System based on Speech and Facial Expression
    </h2>
    <p><b>DESCRIPTION:</b>
      Emotion-based music recommendation is the process of discerning and interpreting human
      emotions through facial expressions and speech recognition to curate personalized music playlists. The objective is
      to develop systems capable of comprehending, interpreting, and responding to emotional cues in order to deliver
      fitting music selections. This field holds significant promise with diverse applications, including enhancing mood
      regulation, therapeutic interventions, immersive entertainment experiences, and personalized user engagement in
      streaming platforms. Deep learning techniques, particularly leveraging transfer learning algorithms, have
      demonstrated effectiveness in constructing models for this purpose. This additionally introduces a real-time
      implementation of emotion-based music recommendation utilizing a web camera, showcasing its efficacy in
      providing accurate emotional cues for music selection. The proposed system promises to revolutionize the way we
      engage with and enjoy music, offering a more personalized and emotionally resonant listening experience.</p>
    <!-- Add more project details as needed -->
  </section>

  
</body>
</html>
